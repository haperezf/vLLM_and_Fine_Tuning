version: "3"
services:
  vllm-openai:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
      - ./models:/models
    environment:
      - HUGGING_FACE_HUB_TOKEN=
    ports:
      - 8000:8000
    ipc: host
    image: vllm/vllm-openai:latest
    command: >
      --model /models/mistral-7b-merged
      --gpu-memory-utilization 0.98
      --max-model-len 2048
      --tensor-parallel-size 1
      --max-num-seqs 64
